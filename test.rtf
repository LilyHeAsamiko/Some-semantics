{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 39.22466379892144\
Iteration 0: w = [ 0.9745142   0.97162242 -0.83189922 -0.83381404] (log-loss = 39.22)\
38.527106895928156\
Iteration 1: w = [ 0.97160352  0.96837813 -0.81336673 -0.81549455] (log-loss = 38.53)\
37.83154369494798\
Iteration 2: w = [ 0.96867679  0.96511546 -0.7948642  -0.79720495] (log-loss = 37.83)\
37.13798527766143\
Iteration 3: w = [ 0.96573397  0.96183442 -0.77639187 -0.77894546] (log-loss = 37.14)\
36.44644305494632\
Iteration 4: w = [ 0.96277502  0.958535   -0.75794998 -0.76071628] (log-loss = 36.45)\
35.75692902642841\
Iteration 5: w = [ 0.95979992  0.95521723 -0.73953876 -0.74251762] (log-loss = 35.76)\
35.06945609150195\
Iteration 6: w = [ 0.95680865  0.95188114 -0.72115847 -0.7243497 ] (log-loss = 35.07)\
34.38403842116446\
Iteration 7: w = [ 0.95380122  0.94852676 -0.70280938 -0.70621276] (log-loss = 34.38)\
33.70069190171585\
Iteration 8: w = [ 0.95077762  0.94515416 -0.68449179 -0.68810707] (log-loss = 33.70)\
33.01943466336688\
Iteration 9: w = [ 0.94773788  0.94176341 -0.66620601 -0.6700329 ] (log-loss = 33.02)\
32.34028770912007\
Iteration 10: w = [ 0.94468203  0.93835457 -0.64795239 -0.65199058] (log-loss = 32.34)\
31.66327566196708\
Iteration 11: w = [ 0.94161011  0.93492775 -0.62973135 -0.63398048] (log-loss = 31.66)\
30.988427651524148\
Iteration 12: w = [ 0.93852217  0.93148304 -0.61154333 -0.61600303] (log-loss = 30.99)\
30.315778364730313\
Iteration 13: w = [ 0.9354183   0.92802058 -0.59338887 -0.59805873] (log-loss = 30.32)\
29.64536928917579\
Iteration 14: w = [ 0.93229858  0.92454048 -0.57526859 -0.58014818] (log-loss = 29.65)\
28.97725018200172\
Iteration 15: w = [ 0.92916312  0.92104291 -0.55718321 -0.56227207] (log-loss = 28.98)\
28.311480802071397\
Iteration 16: w = [ 0.92601204  0.91752804 -0.53913361 -0.54443125] (log-loss = 28.31)\
27.648132948153986\
Iteration 17: w = [ 0.9228455   0.91399604 -0.5211208  -0.5266267 ] (log-loss = 27.65)\
26.987292850995992\
Iteration 18: w = [ 0.91966366  0.91044713 -0.50314599 -0.50885963] (log-loss = 26.99)\
26.32906397207209\
Iteration 19: w = [ 0.91646673  0.90688154 -0.48521063 -0.49113145] (log-loss = 26.33)\
25.673570266020626\
Iteration 20: w = [ 0.91325495  0.90329952 -0.46731644 -0.47344389] (log-loss = 25.67)\
25.020959966554617\
Iteration 21: w = [ 0.91002858  0.89970136 -0.44946548 -0.45579898] (log-loss = 25.02)\
24.371409955951993\
Iteration 22: w = [ 0.90678794  0.89608737 -0.43166019 -0.43819916] (log-loss = 24.37)\
23.725130774600274\
Iteration 23: w = [ 0.90353338  0.89245792 -0.41390349 -0.42064735] (log-loss = 23.73)\
23.082372317504827\
Iteration 24: w = [ 0.90026533  0.8888134  -0.39619882 -0.403147  ] (log-loss = 23.08)\
22.443430246526905\
Iteration 25: w = [ 0.89698425  0.88515425 -0.3785503  -0.38570224] (log-loss = 22.44)\
21.808653117037537\
Iteration 26: w = [ 0.8936907   0.88148097 -0.36096277 -0.36831794] (log-loss = 21.81)\
21.178450171559376\
Iteration 27: w = [ 0.8903853   0.87779413 -0.34344196 -0.35099984] (log-loss = 21.18)\
20.553299686127314\
Iteration 28: w = [ 0.8870688   0.87409437 -0.3259946  -0.33375473] (log-loss = 20.55)\
19.93375766262741\
Iteration 29: w = [ 0.88374202  0.8703824  -0.30862856 -0.31659053] (log-loss = 19.93)\
19.320466537962886\
Iteration 30: w = [ 0.88040592  0.86665905 -0.29135305 -0.29951652] (log-loss = 19.32)\
18.714163426207318\
Iteration 31: w = [ 0.8770616   0.86292523 -0.27417872 -0.28254342] (log-loss = 18.71)\
18.115687224700856\
Iteration 32: w = [ 0.87371031  0.85918199 -0.25711786 -0.26568363] (log-loss = 18.12)\
17.5259837081204\
Iteration 33: w = [ 0.87035345  0.8554305  -0.24018456 -0.24895133] (log-loss = 17.53)\
16.946107525271124\
Iteration 34: w = [ 0.86699264  0.85167209 -0.22339479 -0.23236264] (log-loss = 16.95)\
16.377219835089925\
Iteration 35: w = [ 0.86362966  0.84790824 -0.20676655 -0.21593569] (log-loss = 16.38)\
15.820580220497678\
Iteration 36: w = [ 0.86026649  0.8441406  -0.19031986 -0.19969066] (log-loss = 15.82)\
15.277531564928106\
Iteration 37: w = [ 0.85690533  0.84037099 -0.17407676 -0.18364974] (log-loss = 15.28)\
14.749476836341273\
Iteration 38: w = [ 0.85354857  0.83660143 -0.15806111 -0.16783697] (log-loss = 14.75)\
14.237847256325558\
Iteration 39: w = [ 0.85019878  0.83283411 -0.14229843 -0.15227802] (log-loss = 14.24)\
13.744062160457208\
Iteration 40: w = [ 0.84685866  0.82907137 -0.1268154  -0.13699976] (log-loss = 13.74)\
13.269481938232268\
Iteration 41: w = [ 0.84353107  0.82531571 -0.11163947 -0.12202974] (log-loss = 13.27)\
12.815356647291352\
Iteration 42: w = [ 0.84021891  0.82156974 -0.09679811 -0.10739557] (log-loss = 12.82)\
12.382774011050415\
Iteration 43: w = [ 0.8369251   0.81783617 -0.08231815 -0.09312414] (log-loss = 12.38)\
11.97261126323454\
Iteration 44: w = [ 0.83365249  0.81411773 -0.06822499 -0.07924087] (log-loss = 11.97)\
11.58549544867289\
Iteration 45: w = [ 0.83040384  0.81041713 -0.05454179 -0.06576889] (log-loss = 11.59)\
11.22177618654051\
Iteration 46: w = [ 0.82718169  0.80673702 -0.04128877 -0.05272834] (log-loss = 11.22)\
10.881513587495792\
Iteration 47: w = [ 0.82398835  0.80307992 -0.02848264 -0.04013576] (log-loss = 10.88)\
10.564482219516103\
Iteration 48: w = [ 0.82082583  0.79944817 -0.01613611 -0.02800367] (log-loss = 10.56)\
10.270190102835386\
Iteration 49: w = [ 0.8176958   0.79584391 -0.0042577  -0.01634031] (log-loss = 10.27)\
9.997910070114893\
Iteration 50: w = [ 0.8145996   0.79226898  0.00714831 -0.00514967] (log-loss = 10.00)\
9.746719748060839\
Iteration 51: w = [0.8115382  0.78872498 0.01808173 0.00556842] (log-loss = 9.75)\
9.515546026600731\
Iteration 52: w = [0.80851221 0.78521319 0.02854616 0.01581791] (log-loss = 9.52)\
9.30321013004533\
Iteration 53: w = [0.80552194 0.78173461 0.0385486  0.02560616] (log-loss = 9.30)\
9.108470113203722\
Iteration 54: w = [0.80256739 0.77828994 0.0480989  0.0349434 ] (log-loss = 9.11)\
8.93005854580252\
Iteration 55: w = [0.79964829 0.77487962 0.05720929 0.0438422 ] (log-loss = 8.93)\
8.766714111531506\
Iteration 56: w = [0.79676417 0.77150381 0.06589388 0.052317  ] (log-loss = 8.77)\
8.617206685164817\
Iteration 57: w = [0.79391435 0.76816247 0.07416812 0.06038355] (log-loss = 8.62)\
8.480356085899965\
Iteration 58: w = [0.79109802 0.76485535 0.08204841 0.06805852] (log-loss = 8.48)\
8.355045121618073\
Iteration 59: w = [0.78831424 0.76158204 0.08955171 0.07535911] (log-loss = 8.36)\
8.24022776164075\
Iteration 60: w = [0.78556198 0.75834198 0.09669519 0.08230269] (log-loss = 8.24)\
8.134933348511794\
Iteration 61: w = [0.78284018 0.75513449 0.10349603 0.0889066 ] (log-loss = 8.13)\
8.038267729779097\
Iteration 62: w = [0.78014771 0.75195879 0.10997115 0.0951879 ] (log-loss = 8.04)\
7.949412100445755\
Iteration 63: w = [0.77748344 0.74881405 0.11613707 0.10116322] (log-loss = 7.95)\
7.867620227845326\
Iteration 64: w = [0.77484624 0.74569937 0.1220098  0.10684864] (log-loss = 7.87)\
7.792214605310063\
Iteration 65: w = [0.77223496 0.74261383 0.12760476 0.11225962] (log-loss = 7.79)\
7.7225819627183405\
Iteration 66: w = [0.76964852 0.73955646 0.13293671 0.11741096] (log-loss = 7.72)\
7.658168457944006\
Iteration 67: w = [0.76708582 0.73652632 0.1380197  0.12231673] (log-loss = 7.66)\
7.598474786088661\
Iteration 68: w = [0.76454582 0.73352244 0.1428671  0.12699028] (log-loss = 7.60)\
7.543051373129587\
Iteration 69: w = [0.76202751 0.73054387 0.14749159 0.13144426] (log-loss = 7.54)\
7.49149376573672\
Iteration 70: w = [0.75952992 0.72758968 0.15190513 0.13569061] (log-loss = 7.49)\
7.443438287312441\
Iteration 71: w = [0.75705211 0.72465894 0.15611901 0.13974057] (log-loss = 7.44)\
7.398557999446632\
Iteration 72: w = [0.75459319 0.72175076 0.16014388 0.14360474] (log-loss = 7.40)\
7.3565589857510485\
Iteration 73: w = [0.75215231 0.71886427 0.16398976 0.14729309] (log-loss = 7.36)\
7.317176959507706\
Iteration 74: w = [0.74972867 0.71599864 0.16766608 0.15081496] (log-loss = 7.32)\
7.280174186120037\
Iteration 75: w = [0.74732149 0.71315306 0.1711817  0.15417917] (log-loss = 7.28)\
7.245336704687437\
Iteration 76: w = [0.74493006 0.71032674 0.17454495 0.15739396] (log-loss = 7.25)\
7.212471829106844\
Iteration 77: w = [0.74255367 0.70751895 0.17776365 0.16046709] (log-loss = 7.21)\
7.181405907148002\
Iteration 78: w = [0.74019168 0.70472897 0.18084516 0.16340583] (log-loss = 7.18)\
7.151982315353931\
Iteration 79: w = [0.73784345 0.7019561  0.18379638 0.16621702] (log-loss = 7.15)\
7.124059667939902\
Iteration 80: w = [0.73550841 0.6991997  0.18662382 0.16890709] (log-loss = 7.12)\
7.097510218776998\
Iteration 81: w = [0.733186   0.69645913 0.18933357 0.17148206] (log-loss = 7.10)\
7.072218436815646\
Iteration 82: w = [0.73087569 0.69373381 0.19193137 0.17394759] (log-loss = 7.07)\
7.048079736764112\
Iteration 83: w = [0.72857699 0.69102315 0.19442264 0.17630903] (log-loss = 7.05)\
7.02499934837229\
Iteration 84: w = [0.72628942 0.68832663 0.19681245 0.17857138] (log-loss = 7.02)\
7.002891309204378\
Iteration 85: w = [0.72401254 0.68564371 0.19910558 0.18073936] (log-loss = 7.00)\
6.981677567265411\
Iteration 86: w = [0.72174593 0.68297391 0.20130656 0.18281741] (log-loss = 6.98)\
6.961287181244953\
Iteration 87: w = [0.71948919 0.68031675 0.20341963 0.18480971] (log-loss = 6.96)\
6.941655607439582\
Iteration 88: w = [0.71724193 0.6776718  0.20544881 0.18672022] (log-loss = 6.94)\
6.922724063606608\
Iteration 89: w = [0.71500381 0.67503861 0.20739787 0.18855266] (log-loss = 6.92)\
6.904438961083095\
Iteration 90: w = [0.71277449 0.67241679 0.20927039 0.19031053] (log-loss = 6.90)\
6.886751397479978\
Iteration 91: w = [0.71055363 0.66980595 0.21106975 0.19199716] (log-loss = 6.89)\
6.8696167031360975\
Iteration 92: w = [0.70834095 0.66720573 0.21279913 0.19361568] (log-loss = 6.87)\
6.8529940352982965\
Iteration 93: w = [0.70613615 0.66461576 0.21446157 0.19516905] (log-loss = 6.85)\
6.83684601468893\
Iteration 94: w = [0.70393895 0.66203572 0.21605992 0.19666009] (log-loss = 6.84)\
6.821138399739214\
Iteration 95: w = [0.70174909 0.65946528 0.21759687 0.19809144] (log-loss = 6.82)\
6.805839794313174\
Iteration 96: w = [0.69956634 0.65690415 0.21907501 0.19946562] (log-loss = 6.81)\
6.790921385230091\
Iteration 97: w = [0.69739045 0.65435204 0.22049677 0.20078503] (log-loss = 6.79)\
6.776356706320067\
Iteration 98: w = [0.69522121 0.65180866 0.22186444 0.20205191] (log-loss = 6.78)\
6.762121426123736\
Iteration 99: w = [0.69305839 0.64927376 0.22318023 0.20326842] (log-loss = 6.76)}